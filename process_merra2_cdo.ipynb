{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERRA-2 Daily Processing with CDO (Fast Version)\n",
    "\n",
    "This notebook uses CDO (Climate Data Operators) for much faster processing.\n",
    "\n",
    "## Speed Comparison:\n",
    "- **Python xarray**: ~10-30 seconds per day\n",
    "- **CDO**: ~1-5 seconds per day (5-10x faster!)\n",
    "\n",
    "## What this does:\n",
    "1. Downloads MERRA-2 data using earthaccess\n",
    "2. Uses CDO to:\n",
    "   - Subset spatial region (US Lower 48)\n",
    "   - Select variables (T2M, QV2M, PS)\n",
    "   - Convert T2M to Celsius\n",
    "   - Calculate VPD\n",
    "   - Convert to float32 and compress\n",
    "3. Saves to `daily_data/merra2_us_YYYYMMDD.nc`\n",
    "\n",
    "## Requirements:\n",
    "- CDO must be installed\n",
    "- NCO (netCDF Operators) recommended for additional optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check CDO Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CDO is installed:\n",
      "Climate Data Operators version 2.5.1 (https://mpimet.mpg.de/cdo)\n",
      "\n",
      "✓ NCO is installed (optional):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check if CDO is installed\n",
    "try:\n",
    "    result = subprocess.run(['cdo', '--version'], capture_output=True, text=True)\n",
    "    print(\"✓ CDO is installed:\")\n",
    "    print(result.stdout.split('\\n')[0])\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ CDO is not installed!\")\n",
    "    print(\"\\nInstallation instructions:\")\n",
    "    print(\"  macOS:   brew install cdo\")\n",
    "    print(\"  Ubuntu:  sudo apt-get install cdo\")\n",
    "    print(\"  conda:   conda install -c conda-forge cdo\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check for NCO (optional but helpful)\n",
    "try:\n",
    "    result = subprocess.run(['ncks', '--version'], capture_output=True, text=True)\n",
    "    print(\"\\n✓ NCO is installed (optional):\")\n",
    "    print(result.stdout.split('\\n')[0])\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n⚠ NCO not installed (optional, but recommended for better compression)\")\n",
    "    print(\"  Install: brew install nco  (or conda install -c conda-forge nco)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Authenticate with NASA EarthData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "# Authenticate\n",
    "auth = earthaccess.login()\n",
    "print(\"✓ Authentication successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Date range: 1984-01-01 to 2025-12-31\n",
      "  Bounding box: (-125, 24, -66, 49)\n",
      "  CDO bbox: -125,-66,24,49\n",
      "  Output directory: daily_data\n",
      "  Temp directory: temp_processing\n"
     ]
    }
   ],
   "source": [
    "# US Lower 48 Bounding Box\n",
    "bbox = (-125, 24, -66, 49)  # (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# CDO bbox format: lonmin,lonmax,latmin,latmax\n",
    "cdo_bbox = f\"{bbox[0]},{bbox[2]},{bbox[1]},{bbox[3]}\"\n",
    "\n",
    "# Date range\n",
    "start_date = \"1984-01-01\"\n",
    "end_date = \"2025-12-31\"\n",
    "\n",
    "# MERRA-2 collection\n",
    "collection_id = \"M2T1NXSLV\"\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"daily_data\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Temporary directory for intermediate files\n",
    "temp_dir = Path(\"temp_processing\")\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Date range: {start_date} to {end_date}\")\n",
    "print(f\"  Bounding box: {bbox}\")\n",
    "print(f\"  CDO bbox: {cdo_bbox}\")\n",
    "print(f\"  Output directory: {output_dir}\")\n",
    "print(f\"  Temp directory: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CDO Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "def check_file_exists(date, output_dir):\n",
    "    \"\"\"Check if output file already exists.\"\"\"\n",
    "    if isinstance(date, str):\n",
    "        date = pd.to_datetime(date)\n",
    "    filename = f\"merra2_us_{date.strftime('%Y%m%d')}.nc\"\n",
    "    return (output_dir / filename).exists()\n",
    "\n",
    "\n",
    "def download_merra2_file(date, bbox, collection_id, auth):\n",
    "    \"\"\"\n",
    "    Download MERRA-2 file for a single day using earthaccess.\n",
    "    Returns path to downloaded file or None if not found.\n",
    "    \"\"\"\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    next_day = (date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Search for granule\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=collection_id,\n",
    "        bounding_box=bbox,\n",
    "        temporal=(date_str, next_day),\n",
    "    )\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Download to temp directory\n",
    "    downloaded_files = earthaccess.download(results, temp_dir)\n",
    "    \n",
    "    if len(downloaded_files) > 0:\n",
    "        return downloaded_files[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_vpd_cdo(input_file, output_file, cdo_bbox):\n",
    "    \"\"\"\n",
    "    Process MERRA-2 file using CDO:\n",
    "    1. Subset spatial region\n",
    "    2. Select variables (T2M, QV2M, PS)\n",
    "    3. Convert T2M to Celsius\n",
    "    4. Calculate VPD using CDO expressions\n",
    "    5. Save as compressed float32 NetCDF\n",
    "    \n",
    "    Returns True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_base = temp_dir / f\"temp_{os.getpid()}\"\n",
    "        \n",
    "        # Step 1: Subset region and select variables\n",
    "        subset_file = f\"{temp_base}_subset.nc\"\n",
    "        cmd = [\n",
    "            'cdo', '-f', 'nc4', '-z', 'zip_4',\n",
    "            f'-sellonlatbox,{cdo_bbox}',\n",
    "            '-selname,T2M,QV2M,PS',\n",
    "            input_file,\n",
    "            subset_file\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        \n",
    "        # Step 2: Convert T2M to Celsius and calculate VPD\n",
    "        # VPD calculation using CDO expr\n",
    "        # es = 0.6108 * exp((17.27 * T_celsius) / (T_celsius + 237.3))\n",
    "        # ea = (QV2M * PS) / (0.622 + 0.378 * QV2M) / 1000\n",
    "        # vpd = es - ea\n",
    "        \n",
    "        vpd_expr = (\n",
    "            \"T2M_C=T2M-273.15;\"\n",
    "            \"es=0.6108*exp((17.27*T2M_C)/(T2M_C+237.3));\"\n",
    "            \"ea=(QV2M*PS)/(0.622+0.378*QV2M)/1000;\"\n",
    "            \"VPD=es-ea;\"\n",
    "        )\n",
    "        \n",
    "        calc_file = f\"{temp_base}_calc.nc\"\n",
    "        cmd = [\n",
    "            'cdo', '-f', 'nc4', '-z', 'zip_4',\n",
    "            f'-expr,{vpd_expr}',\n",
    "            subset_file,\n",
    "            calc_file\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        \n",
    "        # Step 3: Rename T2M_C to T2M, then select only T2M and VPD\n",
    "        # Note: CDO operations are chained right-to-left\n",
    "        final_file = f\"{temp_base}_final.nc\"\n",
    "        cmd = [\n",
    "            'cdo', '-f', 'nc4', '-z', 'zip_4',\n",
    "            '-selname,T2M,VPD',\n",
    "            '-chname,T2M_C,T2M',\n",
    "            calc_file,\n",
    "            final_file\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        \n",
    "        # Step 4: Convert to float32 if NCO is available\n",
    "        try:\n",
    "            cmd = [\n",
    "                'ncks', '-O', '-4', '--deflate', '4',\n",
    "                '--ppc', 'default=5',  # 5 significant digits (float32 precision)\n",
    "                final_file,\n",
    "                output_file\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "        except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "            # If NCO not available, just copy the file\n",
    "            import shutil\n",
    "            shutil.copy(final_file, output_file)\n",
    "        \n",
    "        # Clean up temp files\n",
    "        for f in [subset_file, calc_file, final_file]:\n",
    "            if Path(f).exists():\n",
    "                Path(f).unlink()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"CDO error: {e.stderr.decode() if e.stderr else str(e)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_single_day_cdo(date, bbox, cdo_bbox, collection_id, output_dir, temp_dir, auth):\n",
    "    \"\"\"\n",
    "    Complete workflow for processing a single day with CDO.\n",
    "    \"\"\"\n",
    "    if isinstance(date, str):\n",
    "        date = pd.to_datetime(date)\n",
    "    \n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    output_file = output_dir / f\"merra2_us_{date.strftime('%Y%m%d')}.nc\"\n",
    "    \n",
    "    # Check if already processed\n",
    "    if output_file.exists():\n",
    "        return {'success': True, 'message': 'Already exists', 'skipped': True}\n",
    "    \n",
    "    try:\n",
    "        # Download file\n",
    "        input_file = download_merra2_file(date, bbox, collection_id, auth)\n",
    "        \n",
    "        if input_file is None:\n",
    "            return {'success': False, 'message': f'No data found for {date_str}'}\n",
    "        \n",
    "        # Process with CDO\n",
    "        success = calculate_vpd_cdo(input_file, output_file, cdo_bbox)\n",
    "        \n",
    "        # Clean up downloaded file\n",
    "        if Path(input_file).exists():\n",
    "            Path(input_file).unlink()\n",
    "        \n",
    "        if success:\n",
    "            return {'success': True, 'message': f'Processed {date_str}'}\n",
    "        else:\n",
    "            return {'success': False, 'message': f'CDO processing failed for {date_str}'}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {'success': False, 'message': f'Error: {str(e)}'}\n",
    "\n",
    "\n",
    "print(\"Functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Single Day (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 2023-06-01...\n",
      "\n",
      "Result: Already exists\n"
     ]
    }
   ],
   "source": [
    "# Test with a single day\n",
    "test_date = \"2023-06-01\"\n",
    "\n",
    "print(f\"Testing with {test_date}...\\n\")\n",
    "\n",
    "result = process_single_day_cdo(\n",
    "    date=test_date,\n",
    "    bbox=bbox,\n",
    "    cdo_bbox=cdo_bbox,\n",
    "    collection_id=collection_id,\n",
    "    output_dir=output_dir,\n",
    "    temp_dir=temp_dir,\n",
    "    auth=auth\n",
    ")\n",
    "\n",
    "print(f\"Result: {result['message']}\")\n",
    "\n",
    "if result['success'] and not result.get('skipped', False):\n",
    "    # Verify output file\n",
    "    import xarray as xr\n",
    "    test_file = output_dir / f\"merra2_us_{pd.to_datetime(test_date).strftime('%Y%m%d')}.nc\"\n",
    "    ds = xr.open_dataset(test_file)\n",
    "    print(f\"\\nOutput file info:\")\n",
    "    print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "    print(f\"  Dimensions: {dict(ds.dims)}\")\n",
    "    print(f\"  File size: {test_file.stat().st_size / (1024**2):.2f} MB\")\n",
    "    ds.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process All Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate date range\n",
    "dates = pd.date_range(start_date, end_date, freq='D').tolist()\n",
    "\n",
    "print(f\"Total dates to process: {len(dates):,}\\n\")\n",
    "\n",
    "# Check existing files\n",
    "existing = sum(1 for d in dates if check_file_exists(d, output_dir))\n",
    "print(f\"Already processed: {existing:,}\")\n",
    "print(f\"Remaining: {len(dates) - existing:,}\\n\")\n",
    "\n",
    "# Process all days\n",
    "results = {'success': 0, 'failed': 0, 'skipped': 0}\n",
    "\n",
    "for date in tqdm(dates, desc=\"Processing MERRA-2 with CDO\"):\n",
    "    result = process_single_day_cdo(\n",
    "        date=date,\n",
    "        bbox=bbox,\n",
    "        cdo_bbox=cdo_bbox,\n",
    "        collection_id=collection_id,\n",
    "        output_dir=output_dir,\n",
    "        temp_dir=temp_dir,\n",
    "        auth=auth\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        if result.get('skipped', False):\n",
    "            results['skipped'] += 1\n",
    "        else:\n",
    "            results['success'] += 1\n",
    "            if results['success'] % 100 == 0:\n",
    "                print(f\"Processed {results['success']} files...\")\n",
    "    else:\n",
    "        results['failed'] += 1\n",
    "        print(f\"✗ {date.strftime('%Y-%m-%d')}: {result['message']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Successfully processed: {results['success']:,}\")\n",
    "print(f\"Skipped (existing): {results['skipped']:,}\")\n",
    "print(f\"Failed: {results['failed']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Process Date Range (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a specific month or year\n",
    "test_start = \"2023-06-01\"\n",
    "test_end = \"2023-06-30\"\n",
    "\n",
    "test_dates = pd.date_range(test_start, test_end, freq='D').tolist()\n",
    "print(f\"Processing {len(test_dates)} days from {test_start} to {test_end}\\n\")\n",
    "\n",
    "for date in tqdm(test_dates, desc=\"Processing test range\"):\n",
    "    result = process_single_day_cdo(\n",
    "        date=date,\n",
    "        bbox=bbox,\n",
    "        cdo_bbox=cdo_bbox,\n",
    "        collection_id=collection_id,\n",
    "        output_dir=output_dir,\n",
    "        temp_dir=temp_dir,\n",
    "        auth=auth\n",
    "    )\n",
    "    \n",
    "    status = \"✓\" if result['success'] else \"✗\"\n",
    "    print(f\"{status} {date.strftime('%Y-%m-%d')}: {result['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clean Up Temp Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any remaining temp files\n",
    "import shutil\n",
    "\n",
    "temp_files = list(temp_dir.glob(\"*\"))\n",
    "if len(temp_files) > 0:\n",
    "    print(f\"Cleaning up {len(temp_files)} temp files...\")\n",
    "    for f in temp_files:\n",
    "        if f.is_file():\n",
    "            f.unlink()\n",
    "    print(\"✓ Temp directory cleaned\")\n",
    "else:\n",
    "    print(\"✓ Temp directory already clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### CDO Commands Explained:\n",
    "\n",
    "1. **`-sellonlatbox`**: Selects geographic bounding box (much faster than xarray)\n",
    "2. **`-selname`**: Selects only needed variables\n",
    "3. **`-expr`**: Performs calculations (T2M conversion, VPD formula)\n",
    "4. **`-f nc4 -z zip_4`**: NetCDF4 format with compression level 4\n",
    "5. **`ncks --ppc default=5`**: Reduces precision to float32 equivalent\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- CDO operations are ~5-10x faster than xarray\n",
    "- Most time is spent downloading files from NASA\n",
    "- Consider running multiple processes in parallel for even faster processing\n",
    "\n",
    "### Advantages over Python approach:\n",
    "\n",
    "1. **Speed**: Much faster for spatial subsetting and calculations\n",
    "2. **Memory**: Lower memory footprint\n",
    "3. **Battle-tested**: CDO is industry standard for climate data\n",
    "4. **Chainable**: All operations in single command pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
